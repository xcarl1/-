{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1eac3f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0a2cb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#二维卷积==MLP？\n",
    "#stage1\n",
    "def image2embed_naive(image,patch_size,weight):\n",
    "    #image_size:batch_size*channels*h*w\n",
    "    #F.unfold()拿出卷积的区域\n",
    "    patch = F.unfold(image,kernel_size=patch_size,stride=patch_size).transpose(-1,-2) #将图片分块\n",
    "    print(patch.shape)\n",
    "    patch_embedding=patch@weight\n",
    "    return patch_embedding\n",
    "def image2embed_conv(image,kernel,stride):\n",
    "    conv_output=F.conv2d(image,kernel,stride=stride) #batch_size*output_channels*output_h*output_w\n",
    "    batch_size=conv_output.shape[0]\n",
    "    out_channels=conv_output.shape[1]\n",
    "    out_h,out_w=conv_output.shape[2],conv_output.shape[3]\n",
    "    #将oh*ow拉直\n",
    "    patch_embedding = conv_output.reshape((batch_size,out_channels,out_h*out_w)).transpose(-1,-2)\n",
    "    return patch_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fa1381c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48, 8])\n",
      "torch.Size([1, 4, 48])\n",
      "torch.Size([1, 4, 8])\n",
      "torch.Size([1, 4, 48])\n",
      "torch.Size([1, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "#test code for image2embedding\n",
    "batch_size,in_channels,image_h,image_w=1,3,8,8\n",
    "patch_size=4\n",
    "model_dim=8\n",
    "max_num_token=16\n",
    "num_classes=10\n",
    "label=torch.randint(10,(batch_size,))\n",
    "patch_depth=patch_size*patch_size*in_channels\n",
    "image=torch.randn(batch_size,in_channels,image_h,image_w)\n",
    "weight=torch.randn(patch_depth,model_dim)\n",
    "print(weight.shape)\n",
    "print(image2embed_naive(image,patch_size,weight).shape)\n",
    "patch_embedding=image2embed_naive(image,patch_size,weight)\n",
    "#kernel的形状因该是out_channels*in_channels*h*w\n",
    "kernel=weight.transpose(0,1).reshape((-1,in_channels,patch_size,patch_size))\n",
    "print(image2embed_conv(image,kernel,patch_size).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be7a4983",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stage2\n",
    "cls_token_embedding=torch.randn(batch_size,1,model_dim,requires_grad=True)\n",
    "token_embedding=torch.cat([cls_token_embedding,patch_embedding],dim=1)\n",
    "position_embedding_table=torch.randn(max_num_token,model_dim,requires_grad=True)\n",
    "seq_len=token_embedding.shape[1]\n",
    "position_embedding=torch.tile(position_embedding_table[:seq_len],[token_embedding.shape[0],1,1])\n",
    "token_embedding+=position_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01a8863a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 8])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#用torch.nn.TransformerEncoder(encoder_layer,num_layers,norm=None)\n",
    "encoder_layer = nn.TransformerEncoderLayer(d_model=model_dim, nhead=8)\n",
    "transformer_encoder=nn.TransformerEncoder(encoder_layer,num_layers=6)\n",
    "encoder_output=transformer_encoder(token_embedding)\n",
    "encoder_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "98649360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4])\n",
      "tensor(3.2685, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "cls_token_output=encoder_output[:,0,:]\n",
    "cls_head=nn.Linear(model_dim,num_classes)\n",
    "logits=cls_head(cls_token_output)\n",
    "loss_fn=nn.CrossEntropyLoss()\n",
    "loss=loss_fn(logits,label)\n",
    "print(label)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bc7acf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
